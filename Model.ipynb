{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import datetime, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: \n",
      "all_NSP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>DR</th>\n",
       "      <th>LB</th>\n",
       "      <th>AC.1</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110092</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472441</td>\n",
       "      <td>0.587156</td>\n",
       "      <td>0.403670</td>\n",
       "      <td>0.271375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>627</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165138</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.044610</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>602</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165138</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>781</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>614</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.040892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration        AC   FM        UC     DL   DS   DP   DR        LB  \\\n",
       "0       117  0.000000  0.0  0.000000  0.000  0.0  0.0  0.0  0.259259   \n",
       "1       627  0.153846  0.0  0.173913  0.125  0.0  0.0  0.0  0.481481   \n",
       "2       602  0.076923  0.0  0.217391  0.125  0.0  0.0  0.0  0.500000   \n",
       "3       781  0.076923  0.0  0.260870  0.125  0.0  0.0  0.0  0.518519   \n",
       "4       614  0.153846  0.0  0.217391  0.000  0.0  0.0  0.0  0.481481   \n",
       "\n",
       "       AC.1  ...       Min       Max      Nmax  Nzeros      Mode      Mean  \\\n",
       "0  0.000000  ...  0.110092  0.034483  0.111111     0.0  0.472441  0.587156   \n",
       "1  0.315789  ...  0.165138  0.655172  0.333333     0.1  0.637795  0.577982   \n",
       "2  0.157895  ...  0.165138  0.655172  0.277778     0.1  0.637795  0.568807   \n",
       "3  0.157895  ...  0.027523  0.413793  0.611111     0.0  0.606299  0.559633   \n",
       "4  0.368421  ...  0.027523  0.413793  0.500000     0.0  0.606299  0.577982   \n",
       "\n",
       "     Median  Variance  Tendency  NSP  \n",
       "0  0.403670  0.271375       1.0    2  \n",
       "1  0.577982  0.044610       0.5    1  \n",
       "2  0.559633  0.048327       0.5    1  \n",
       "3  0.550459  0.048327       1.0    1  \n",
       "4  0.559633  0.040892       1.0    1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the preprocessed file we made\n",
    "print(\"File name: \") \n",
    "file_name = input()\n",
    "\n",
    "dataFrame = pd.read_csv(r'data/p/' + file_name + '.csv')\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 29 features\n"
     ]
    }
   ],
   "source": [
    "num_features = dataFrame.shape[1] - 1\n",
    "print(\"We have \" + str(num_features) + \" features\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSP\n"
     ]
    }
   ],
   "source": [
    "target_name = input()\n",
    "y = dataFrame.pop(target_name)\n",
    "X = dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 ... 2 2 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# binary encode\n",
    "y = np.array(y)\n",
    "print(y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "y = onehot_encoder.fit_transform(y.reshape(-1, 1))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1530, 20)\n",
      "(383, 20)\n",
      "(213, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=False)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will be used for the NSP classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, input_dim=num_features, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(3\n",
    "                    , activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 1530 samples, validate on 383 samples\n",
      "Epoch 1/100\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 2/100\n",
      "1530/1530 [==============================] - 0s 44us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 3/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 4/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 5/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 6/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 7/100\n",
      "1530/1530 [==============================] - 0s 38us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 8/100\n",
      "1530/1530 [==============================] - 0s 38us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 9/100\n",
      "1530/1530 [==============================] - 0s 43us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 10/100\n",
      "1530/1530 [==============================] - 0s 40us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 11/100\n",
      "1530/1530 [==============================] - 0s 40us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 12/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 13/100\n",
      "1530/1530 [==============================] - 0s 39us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 14/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 15/100\n",
      "1530/1530 [==============================] - 0s 39us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 16/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 17/100\n",
      "1530/1530 [==============================] - 0s 34us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 18/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 19/100\n",
      "1530/1530 [==============================] - 0s 38us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 20/100\n",
      "1530/1530 [==============================] - 0s 41us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 21/100\n",
      "1530/1530 [==============================] - 0s 38us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 22/100\n",
      "1530/1530 [==============================] - 0s 50us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 23/100\n",
      "1530/1530 [==============================] - 0s 53us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 24/100\n",
      "1530/1530 [==============================] - 0s 42us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 25/100\n",
      "1530/1530 [==============================] - 0s 40us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 26/100\n",
      "1530/1530 [==============================] - 0s 38us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 27/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 28/100\n",
      "1530/1530 [==============================] - 0s 38us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 29/100\n",
      "1530/1530 [==============================] - 0s 40us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 30/100\n",
      "1530/1530 [==============================] - 0s 38us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 31/100\n",
      "1530/1530 [==============================] - 0s 49us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 32/100\n",
      "1530/1530 [==============================] - 0s 47us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 33/100\n",
      "1530/1530 [==============================] - 0s 41us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 34/100\n",
      "1530/1530 [==============================] - 0s 44us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 35/100\n",
      "1530/1530 [==============================] - 0s 45us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 36/100\n",
      "1530/1530 [==============================] - 0s 37us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 37/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 38/100\n",
      "1530/1530 [==============================] - 0s 34us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 39/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 40/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 41/100\n",
      "1530/1530 [==============================] - 0s 37us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 42/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 43/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 44/100\n",
      "1530/1530 [==============================] - 0s 37us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 45/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 46/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 47/100\n",
      "1530/1530 [==============================] - 0s 34us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 48/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 49/100\n",
      "1530/1530 [==============================] - 0s 37us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 50/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 51/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 52/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 53/100\n",
      "1530/1530 [==============================] - 0s 37us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "1530/1530 [==============================] - 0s 34us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 55/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 56/100\n",
      "1530/1530 [==============================] - 0s 39us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 57/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 58/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 59/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 60/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 61/100\n",
      "1530/1530 [==============================] - 0s 34us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 62/100\n",
      "1530/1530 [==============================] - 0s 34us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 63/100\n",
      "1530/1530 [==============================] - 0s 34us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 64/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 65/100\n",
      "1530/1530 [==============================] - 0s 37us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 66/100\n",
      "1530/1530 [==============================] - 0s 34us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 67/100\n",
      "1530/1530 [==============================] - 0s 34us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 68/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 69/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 70/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 71/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 72/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 73/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 74/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 75/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 76/100\n",
      "1530/1530 [==============================] - 0s 34us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 77/100\n",
      "1530/1530 [==============================] - 0s 34us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 78/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 79/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 80/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 81/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 82/100\n",
      "1530/1530 [==============================] - 0s 34us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 83/100\n",
      "1530/1530 [==============================] - 0s 34us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 84/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 85/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 86/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 87/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 88/100\n",
      "1530/1530 [==============================] - 0s 37us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 89/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 90/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 91/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 92/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 93/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 94/100\n",
      "1530/1530 [==============================] - 0s 37us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 95/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 96/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 97/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 98/100\n",
      "1530/1530 [==============================] - 0s 36us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 99/100\n",
      "1530/1530 [==============================] - 0s 39us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n",
      "Epoch 100/100\n",
      "1530/1530 [==============================] - 0s 35us/sample - loss: 10.7232 - accuracy: 0.1843 - val_loss: 11.0095 - val_accuracy: 0.0209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1427fab90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorboard stuff\n",
    "log_dir = os.path.join(\n",
    "    \"logs\",\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "          epochs=100,\n",
    "          validation_data=(X_val, y_val),\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
